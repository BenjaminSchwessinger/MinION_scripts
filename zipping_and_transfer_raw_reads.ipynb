{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a draft version to get the MinION reads zipped up a certain way and moved over to a specific HPC for basecalling.\n",
    "\n",
    "Idea is to point the program towards the reads directory of MinKNOW, zip them up and move them over to a server"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 197,
   "metadata": {},
=======
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
   "outputs": [],
   "source": [
    "#for now name the initial BASEFOLDER, BACKUPFOLDER, NUMBEROFFOLDERS, SEQUENCINGRUN, RTARGETFOLDER\n",
    "#\n",
    "#later this will come from the config %%file\n",
<<<<<<< HEAD
    "CONFIGFILE = '/mnt/d/Data/reads/MinION_scripts-master/ZipTra.cfg'"
=======
    "CONFIGFILE = '/Users/ben/Documents/work_related/Canberra/Python_and_R_scripts/MinION/scripts/ZipTra.cfg'"
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 198,
   "metadata": {},
=======
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import subprocess\n",
<<<<<<< HEAD
    "import configparser \n",
    "import argparse"
=======
    "import configparser "
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 199,
   "metadata": {},
=======
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "['/mnt/d/Data/reads/MinION_scripts-master/ZipTra.cfg']"
      ]
     },
     "execution_count": 199,
=======
       "['/Users/ben/Documents/work_related/Canberra/Python_and_R_scripts/MinION/scripts/ZipTra.cfg']"
      ]
     },
     "execution_count": 12,
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config = configparser.ConfigParser()\n",
    "Config.read(CONFIGFILE)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 200,
=======
   "execution_count": 13,
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConfigSectionMap(section):\n",
    "    dict1 = {}\n",
    "    options = Config.options(section)\n",
    "    for option in options:\n",
    "        try:\n",
    "            dict1[option] = Config.get(section, option)\n",
    "            if dict1[option] == -1:\n",
    "                DebugPrint(\"skip: %s\" % option)\n",
    "        except:\n",
    "            print(\"exception on %s!\" % option)\n",
    "            dict1[option] = None\n",
    "    return dict1"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 201,
   "metadata": {},
=======
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
   "outputs": [],
   "source": [
    "DIRS = ConfigSectionMap('Directories')\n",
    "BACKUPFOLDER = DIRS['backupfolder']\n",
    "BASEFOLDER = DIRS['basefolder']\n",
    "RTARGETFOLDER = DIRS['rtargetfolder']"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 202,
=======
   "execution_count": 28,
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SETUP = ConfigSectionMap('Zip settings')\n",
    "NUMBEROFFOLDERS = int(SETUP['numberoffolders'])\n",
    "SEQUENCINGRUN = SETUP['sequencingrun']"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 203,
   "metadata": {},
=======
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
   "outputs": [],
   "source": [
    "#now check if basefolder is there\n",
    "if not os.path.exists(BASEFOLDER):\n",
    "    print('Check basefolder')\n",
    "    exit\n",
    "if not os.path.exists(BACKUPFOLDER):\n",
    "    print('Backup folder %s does not exist. Creating it.' %BACKUPFOLDER)\n",
    "    os.mkdir(BACKUPFOLDER)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 204,
   "metadata": {},
=======
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
   "outputs": [],
   "source": [
    "#get all the the folders witht the SEQUENCINGRUN ID in the basefolder\n",
    "_id = re.compile(SEQUENCINGRUN, re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 205,
   "metadata": {},
=======
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
   "outputs": [],
   "source": [
    "#now get all the folders belonging to this sequencing %run\n",
    "read_folder_list = [os.path.join(BASEFOLDER, x) for x in os.listdir(BASEFOLDER)]\n",
    "flowcellfolder = [x for x in read_folder_list if _id.search(x) != None]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 206,
   "metadata": {},
=======
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
   "outputs": [],
   "source": [
    "#now check if in the target folder is fast5 folder\n",
    "def check_fast5(x):\n",
    "    if not os.path.exists(os.path.join(x, 'fast5')):\n",
    "        return False\n",
    "    elif not os.path.isdir(os.path.join(x, 'fast5')):\n",
    "        return False\n",
    "    else:\n",
    "        fast5path = os.path.join(x, 'fast5')\n",
    "        #now check if the first folder contains fast5 files\n",
    "        subfolders = [os.path.join(fast5path, x) for x in os.listdir(fast5path)]\n",
    "        if len(subfolders) == 0:\n",
    "            return False\n",
    "        else:\n",
    "            content = [x for x in os.listdir(subfolders[0]) if x.endswith('.fast5')]\n",
    "            if len(content) == 0:\n",
    "                return False\n",
    "            else:\n",
<<<<<<< HEAD
    "                #print(content)\n",
=======
    "                print(content)\n",
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
    "                return True"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 213,
=======
   "execution_count": 21,
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tar_zip(fast5_folder,backupfolder, start, end):\n",
    "    command_list = []\n",
<<<<<<< HEAD
    "    tar_command = 'tar -cvzf'\n",
=======
    "    tar_command = 'tar -czf'\n",
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
    "    command_list.append(tar_command)\n",
    "    folder = fast5_folder.split('/')[-2]\n",
    "    target = os.path.join(backupfolder,'%s_%s_%s.tar.gz' % (folder, start, end))\n",
    "    command_list.append(target)\n",
    "    tar_input = '%s/{%s..%s}'%(fast5_folder, start, end)\n",
    "    command_list.append(tar_input)\n",
    "    comand = ' '.join(command_list)\n",
    "    print(comand)\n",
    "    #here add in the subprocess\n",
<<<<<<< HEAD
    "    comand_stderr = subprocess.call(comand, shell=True)\n",
    "    "
=======
    "    return comand"
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 214,
   "metadata": {},
=======
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
   "outputs": [],
   "source": [
    "def zip_and_backup(x, number, backupfolder):\n",
    "    fast5path = os.path.join(x, 'fast5')\n",
    "    #get the runs folder id\n",
    "    folder = x.split('/')[-1]\n",
    "    subfolders = [os.path.join(fast5path, x) for x in os.listdir(fast5path)]\n",
    "    noffolders = len(subfolders)\n",
    "    #noffolders = 300\n",
    "    print(\"We have %i of folders to zip up.\" % noffolders) \n",
    "    if noffolders <= number:\n",
    "        start = 0\n",
    "        end = noffolders - 1\n",
    "        tar_zip(fast5path,backupfolder, start, end)\n",
    "    elif noffolders > number:\n",
    "        if number == 1:\n",
    "            starts = [x for x in range(0, noffolders, number)]\n",
    "            ends = starts\n",
    "            start_end_zip = zip(starts, ends)\n",
    "            for x in start_end_zip:\n",
    "                start, end = x\n",
    "                tar_zip(fast5path,backupfolder, start, end)\n",
    "        else:\n",
    "            start = 0\n",
<<<<<<< HEAD
    "            while start < noffolders - number:\n",
    "                end = start + number - 1\n",
=======
    "            while start < noffolders -number:\n",
    "                end = start + number -1\n",
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
    "                tar_zip(fast5path,backupfolder, start, end)\n",
    "                start = start + number\n",
    "            start = end + 1\n",
    "            end = noffolders -1\n",
    "            tar_zip(fast5path,backupfolder, start, end)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 215,
   "metadata": {
=======
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "We have 26 of folders to zip up.\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_0_0.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{0..0}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_1_1.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{1..1}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_2_2.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{2..2}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_3_3.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{3..3}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_4_4.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{4..4}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_5_5.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{5..5}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_6_6.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{6..6}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_7_7.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{7..7}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_8_8.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{8..8}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_9_9.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{9..9}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_10_10.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{10..10}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_11_11.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{11..11}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_12_12.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{12..12}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_13_13.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{13..13}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_14_14.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{14..14}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_15_15.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{15..15}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_16_16.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{16..16}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_17_17.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{17..17}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_18_18.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{18..18}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_19_19.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{19..19}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_20_20.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{20..20}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_21_21.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{21..21}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_22_22.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{22..22}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_23_23.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{23..23}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_24_24.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{24..24}\n",
      "tar -cvzf /mnt/d/Data/reads/backup/20171221_1103_20171221_FAH34985_25_25.tar.gz /mnt/d/Data/reads/workspace/20171221_1103_20171221_FAH34985/fast5/{25..25}\n"
=======
      "['some.fast5']\n",
      "We have 2 of folders to zip up.\n",
      "tar -czf /Users/ben/Documents/work_related/Canberra/Python_and_R_scripts/MinION/backup/date_number_NAME_FLOWID_0_0.tar.gz /Users/ben/Documents/work_related/Canberra/Python_and_R_scripts/MinION/date_number_NAME_FLOWID/fast5/{0..0}\n",
      "tar -czf /Users/ben/Documents/work_related/Canberra/Python_and_R_scripts/MinION/backup/date_number_NAME_FLOWID_1_1.tar.gz /Users/ben/Documents/work_related/Canberra/Python_and_R_scripts/MinION/date_number_NAME_FLOWID/fast5/{1..1}\n"
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
     ]
    }
   ],
   "source": [
    "#now zip up all the folders\n",
    "for x in flowcellfolder:\n",
    "    if check_fast5(x) == True:\n",
    "        zip_and_backup(x, NUMBEROFFOLDERS,  BACKUPFOLDER)\n",
    "    else:\n",
    "        print('%s does not contain any fast5 files in folder 0')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 179,
   "metadata": {},
=======
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
   "outputs": [],
   "source": [
    "def scp_zip(file, destination):\n",
    "    command_list = []\n",
    "    command_list.append('scp ')\n",
    "    command_list.append('%s '%file)\n",
    "    command_list.append('%s'%destination)\n",
    "    command = ' '.join(command_list)\n",
    "    #here add subprocess\n",
<<<<<<< HEAD
    "    print(command)\n",
    "    command_stderr = subprocess.check_output(command, shell=True, stderr=subprocess.STDOUT)"
=======
    "    print(command)"
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 164,
   "metadata": {},
=======
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
   "outputs": [],
   "source": [
    "for file in [os.path.join(BACKUPFOLDER, x) for x in BACKUPFOLDER if x.endswith('tar.gz')]:\n",
    "    print(file)\n",
    "    scp_zip(file, RTARGETFOLDER)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ben/Documents/work_related/Canberra/Python_and_R_scripts/MinION/backup/agae.tar.gz\n",
      "scp  /Users/ben/Documents/work_related/Canberra/Python_and_R_scripts/MinION/backup/agae.tar.gz  bxs800@r-dm.nci.org.au:/short/xf3/bxs800/test\n"
     ]
    }
   ],
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
   "source": [
    "for file in [os.path.join(BACKUPFOLDER, x) for x in os.listdir(BACKUPFOLDER) if x.endswith('tar.gz')]:\n",
    "    print(file)\n",
    "    scp_zip(file, RTARGETFOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
=======
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.6.1"
=======
   "version": "3.5.2"
>>>>>>> e2f3d5a51183c44d81f385d0a412e810ebbbfee3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
